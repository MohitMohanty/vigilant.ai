# ğŸ‘ï¸ğŸ¤– Real-Time Vision Intelligence (Prompt-Driven AI)

> **Can AI sense when itâ€™s being watched?**  
This project demonstrates a **real-time, prompt-driven Vision Intelligence system** that doesnâ€™t just detect objects â€” it **understands scenes, intent, and behavior** using Vision-Language Models.

---

## ğŸš€ Project Overview

This application connects a live camera feed to a **Vision-Language Model (VLM)** and allows users to **dynamically change prompts** to control what the AI analyzes â€” *without retraining or restarting the system*.

The same camera can instantly switch roles:
- From general scene understanding  
- To behavior detection  
- To safety monitoring  
- To security surveillance  

All controlled purely through **natural-language prompts**.

---

## ğŸ¥ What Happens in the Demo

1. The AI first **describes the live scene** in front of the camera in natural language  
2. The prompt is then changed in real time to:  
   > *â€œCheck if the person is using a smartphoneâ€*  
3. The AI immediately adapts and **correctly detects smartphone usage**  
4. No model retraining, no rule changes â€” just **prompt-based intelligence**

---

## ğŸ” Why This Is Different

Traditional systems rely on fixed object detection and hard-coded rules.

This system enables:
- ğŸ”„ Dynamic task switching  
- ğŸ§  Contextual reasoning  
- ğŸ“¹ Per-camera custom intelligence  
- ğŸ“ Real-time text alerts  

---

## ğŸ§ª Example Prompt-Driven Use Cases

- ğŸ¦º Alert if a worker is not wearing safety equipment  
- ğŸ”¥ Detect fire, smoke, or sparks  
- ğŸ“µ Detect mobile phone usage in restricted zones  
- ğŸš§ Identify unsafe behavior near machinery  
- ğŸ‘¥ Detect overcrowding or abnormal movement  
- ğŸš« Alert if someone enters a restricted area  
- ğŸ›¡ï¸ Identify suspicious perimeter activity  

---

## ğŸ­ Potential Application Areas

- Industrial safety & compliance  
- Manufacturing & warehouses  
- Smart surveillance  
- Defense & perimeter security  
- Critical infrastructure  
- Airports & high-security zones  

---

## ğŸ§  Technology Stack

**Hardware**
- NVIDIA RTX 3050 (6GB VRAM)

**AI Models**
- Gemma 3  
- Qwen2.5-VL  
- Served locally via Ollama

**Software**
- Python  
- OpenCV  
- PyQt6  

---

## âš™ï¸ How to Run

```bash
python vision-app.py
```

Ensure:
- Webcam is connected  
- Ollama is running locally  

---

## ğŸ’¡ Key Takeaway

**Vision + Language + Prompts = Adaptive Intelligence**

---

## ğŸ¤ Open to
- Collaborations  
- Real-world deployments  
- AI / Computer Vision roles  

---
## Screenshots

<img width="1920" height="1080" alt="Screenshot 2026-01-15 120459" src="https://github.com/user-attachments/assets/55123495-b452-45d4-b32c-8003f5b2d70b" />



## ğŸ”– Tags
#AI #ComputerVision #EdgeAI #IndustrialAI #DefenseTech #Python #NVIDIA #RTX #Ollama
